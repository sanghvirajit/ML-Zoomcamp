![reading_plan](https://user-images.githubusercontent.com/69073063/134175192-79549752-3529-42b9-bd21-31b1f3156f17.png)

<div id="readme" class="Box-body readme blob js-code-block-container p-5 p-xl-6 gist-border-0">
    <article class="markdown-body entry-content container-lg" itemprop="text"><h1><a id="user-content-machine-learning-bookcamp" class="anchor" aria-hidden="true" href="#machine-learning-bookcamp"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Machine Learning Bookcamp</h1>
<p>The code from the Machine Learning Bookcamp book</p>
<p>Useful links:</p>
<ul>
<li><a href="https://mlbookcamp.com" rel="nofollow">https://mlbookcamp.com</a>: supplimentary materials</li>
<li><a href="https://datatalks.club" rel="nofollow">https://datatalks.club</a>: the place to talk about data (and the book: join the <code>#ml-bookcamp</code> channel to ask questions about the book and report any problems)</li>
</ul>
<h2><a id="user-content-machine-learning-zoomcamp" class="anchor" aria-hidden="true" href="#machine-learning-zoomcamp"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Machine Learning Zoomcamp</h2>
<p>ML Zoomcamp is a course based on the book</p>
<ul>
<li>It's online and free</li>
<li>The course starts on September, 6</li>
<li>It's possible to join at any moment</li>
</ul>
<h1><a id="user-content-chapters" class="anchor" aria-hidden="true" href="#chapters"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Chapters</h1>
<h2><a id="user-content-chapter-1-introduction-to-machine-learning" class="anchor" aria-hidden="true" href="#chapter-1-introduction-to-machine-learning"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Chapter 1: Introduction to Machine Learning</h2>
<ul>
<li>Understanding machine learning and the problems it can solve</li>
<li>CRISP-DM: Organizing a successful machine learning project</li>
<li>Training and selecting machine learning models</li>
<li>Performing model validation</li>
</ul>
<h2><a id="user-content-chapter-2-machine-learning-for-regression" class="anchor" aria-hidden="true" href="#chapter-2-machine-learning-for-regression"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Chapter 2: Machine Learning for Regression</h2>
<ul>
<li>Creating a car-price prediction project with a linear regression model</li>
<li>Doing an initial exploratory data analysis with Jupyter notebooks</li>
<li>Setting up a validation framework</li>
<li>Implementing the linear regression model from scratch</li>
<li>Performing simple feature engineering for the model</li>
<li>Keeping the model under control with regularization</li>
<li>Using the model to predict car prices</li>
</ul>
<h2><a id="user-content-chapter-3-machine-learning-for-classification" class="anchor" aria-hidden="true" href="#chapter-3-machine-learning-for-classification"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Chapter 3: Machine Learning for Classification</h2>
<ul>
<li>Predicting customers who will churn with logistic regression</li>
<li>Doing exploratory data analysis for identifying important features</li>
<li>Encoding categorical variables to use them in machine learning models</li>
<li>Using logistic regression for classification</li>
</ul>
<h2><a id="user-content-chapter-4-evaluation-metrics-for-classification" class="anchor" aria-hidden="true" href="#chapter-4-evaluation-metrics-for-classification"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Chapter 4: Evaluation Metrics for Classification</h2>
<ul>
<li>Accuracy as a way of evaluating binary classification models and its limitations</li>
<li>Determining where our model makes mistakes using a confusion table</li>
<li>Deriving other metrics like precision and recall from the confusion table</li>
<li>Using ROC and AUC to further understand the performance of a binary classification model</li>
<li>Cross-validating a model to make sure it behaves optimally</li>
<li>Tuning the parameters of a model to achieve the best predictive performance</li>
</ul>
<h2><a id="user-content-chapter-5-deploying-machine-learning-models" class="anchor" aria-hidden="true" href="#chapter-5-deploying-machine-learning-models"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Chapter 5: Deploying Machine Learning Models</h2>
<ul>
<li>Saving models with Pickle</li>
<li>Serving models with Flask</li>
<li>Managing dependencies with Pipenv</li>
<li>Making the service self-contained with Docker</li>
<li>Deploying it to the cloud using AWS Elastic Beanstalk</li>
</ul>
<h2><a id="user-content-chapter-6-decision-trees-and-ensemble-learning" class="anchor" aria-hidden="true" href="#chapter-6-decision-trees-and-ensemble-learning"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Chapter 6: Decision Trees and Ensemble Learning</h2>
<ul>
<li>Predicting the risk of default with tree-based models</li>
<li>Decision trees and the decision tree learning algorithm</li>
<li>Random forest: putting multiple trees together into one model</li>
<li>Gradient boosting as an alternative way of combining decision trees</li>
</ul>
<h2><a id="user-content-chapter-7-neural-networks-and-deep-learning" class="anchor" aria-hidden="true" href="#chapter-7-neural-networks-and-deep-learning"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Chapter 7: Neural Networks and Deep Learning</h2>
<ul>
<li>Convolutional neural networks for image classification</li>
<li>TensorFlow and Keras — frameworks for building neural networks</li>
<li>Using pre-trained neural networks</li>
<li>Internals of a convolutional neural network</li>
<li>Training a model with transfer learning</li>
<li>Data augmentations — the process of generating more training data</li>
</ul>
<h2><a id="user-content-chapter-8-serverless-deep-learning" class="anchor" aria-hidden="true" href="#chapter-8-serverless-deep-learning"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Chapter 8: Serverless Deep Learning</h2>
<ul>
<li>Serving models with TensorFlow-Lite — a light-weight environment for applying TensorFlow models</li>
<li>Deploying deep learning models with AWS Lambda</li>
<li>Exposing the Lambda function as a web service via API Gateway</li>
</ul>
<h2><a id="user-content-chapter-9-kubernetes-and-kubeflow" class="anchor" aria-hidden="true" href="#chapter-9-kubernetes-and-kubeflow"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Chapter 9: Kubernetes and Kubeflow</h2>
<ul>
<li>Understanding different methods of deploying and serving models in the cloud.</li>
<li>Serving Keras and TensorFlow models with TensorFlow-Serving</li>
<li>Deploying TensorFlow-Serving to Kubernetes</li>
</ul>
  </body>
</html>

